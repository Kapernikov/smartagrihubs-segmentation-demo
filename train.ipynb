{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from processing.preprocessing import generate_categories_dict\n",
    "from processing.postprocessing import create_color_map\n",
    "\n",
    "import namegenerator as namegen\n",
    "from models.model_functions import create_model, load_model\n",
    "from models.train_test.train import train_model\n",
    "from models.saving import (load_params, save_losses, save_model, save_params)\n",
    "from utils.dir_processing import save_metadata\n",
    "from utils.utils import create_metadata\n",
    "\n",
    "from processing.preprocessing import preprocess_data_from_images_dev\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if laptop has a GPU available for computation\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Disabling logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment variables\n",
    "cfg = OmegaConf.load('configs/env.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = cfg.MODEL.categories\n",
    "categories_dict = generate_categories_dict(categories)\n",
    "color_map = create_color_map(categories)\n",
    "\n",
    "num_classes = len(categories) + 1\n",
    "\n",
    "desired_input_dimensions = eval(cfg.DATA.img_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model or create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.MODEL.model_name == '': \n",
    "    model_name = namegen.gen(separator='_')\n",
    "\n",
    "    model = create_model(desired_input_dimensions, num_classes, cfg.TRAINING.filters, cfg.HYPERSPECTRAL.hyperspec, cfg.HYPERSPECTRAL.pca)\n",
    "else:\n",
    "    model_name = cfg.MODEL.model_name\n",
    "\n",
    "    model = load_model(model_name)\n",
    "    load_params(model_name)\n",
    "\n",
    "PATH_LOG = os.path.join(cfg.DIRS.history, model_name)  # store model log\n",
    "PATH_RES = os.path.join(cfg.DIRS.results, model_name)  # store results\n",
    "\n",
    "os.makedirs(PATH_LOG, exist_ok=True)\n",
    "os.makedirs(os.path.join(PATH_RES, model_name), exist_ok=True)\n",
    "\n",
    "metadata = create_metadata(model_name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET LOADING AND PREPROCESSING === #\n",
    "X, y = preprocess_data_from_images_dev(data_path = cfg.DIRS.data, \n",
    "                                       shape = desired_input_dimensions,\n",
    "                                       categories=categories,\n",
    "                                       hspectral = [cfg.HYPERSPECTRAL.hyperspec, cfg.HYPERSPECTRAL.pca])\n",
    "\n",
    "#=== TRAIN/TEST SPLIT === #\n",
    "test_size = 1.- cfg.DATA.train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=cfg.DATA.seed)\n",
    "\n",
    "print(f'Number of TRAIN images: {len(X_train)}')\n",
    "print(f'Number of TEST images: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == TRAINING == #\n",
    "history = train_model(model, PATH_RES, model_name, Xs=X_train, Ys=y_train)\n",
    "        \n",
    "# == Saving model informations == #\n",
    "save_losses(history, PATH_RES)\n",
    "save_model(model, PATH_LOG)\n",
    "save_metadata(metadata, PATH_LOG)\n",
    "save_params(PATH_LOG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "655936058c9faa9280730ea635086effdc23d6308265a7763ad2c8854fe885a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
