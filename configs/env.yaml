# Environment class that will be saved for each model ( some parameters are not included in the saving )
  # Categories that we want to predict, all other categories will be considered as background
  predictable_categories: ['object'] #['crack', 'hole', 'cut'] #[ 'cashew', 'peanut' ]

  # Indicate the model folder name to load a model, keep it empty to create a new model
  model_name: '' #"wimpy_magenta_eel"
  loaded_timestamp: ''
  train: True
  test: True

  # Data configuration
  train_test_split: 0.7
  desired_input_dimensions: (256, 256)  # Width, Height
  use_non_annotated_images_train: False
  use_non_annotated_images_test: False
  num_of_non_annotated_images_train: 0
  num_of_non_annotated_images_test: 160
  use_data_generator: False
  seed: 99

  # Training configuration
  num_epochs: 100
  validation_split: 0.5
  filters: [32, 64, 128, 256]
  # batch_size = 58  # 64 ( issue could be because of passing a big list of samples )
  batch_size: 16
  dropout_rate: 0.5
  verbose: 1
  shuffle: True
  validation_split: 0.3
  loss_name: 'focal_tversky_loss'
  metrics_name: [ 'OneHotMeanIoU' ]

  optimizer_name: 'sgd'
  learning_rate: 0.1
  #decay= learning_rate/num_epochs

   # 6D configs: full hyperspectral or PCA reduced
  hyperspec: False  
  pca: False 

  # Additional informations
  additional: ''



