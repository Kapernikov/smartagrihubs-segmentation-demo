{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from processing.preprocessing import generate_categories_dict\n",
    "from processing.postprocessing import create_color_map\n",
    "\n",
    "from models.model_functions import load_model\n",
    "from models.saving import load_params\n",
    "from utils.dir_processing import save_metadata\n",
    "from utils.utils import create_metadata\n",
    "\n",
    "from models import evaluate\n",
    "from models.train_test.test import test_model\n",
    "\n",
    "from processing.preprocessing import preprocess_data_from_images_dev\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.saving import save_predictions\n",
    "\n",
    "from processing.postprocessing import encode_masks_to_rgb\n",
    "from utils.dir_processing import clean_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if laptop has a GPU available for computation\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Disabling logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment variables\n",
    "cfg = OmegaConf.load('configs/env.yaml')\n",
    "\n",
    "categories = cfg.MODEL.categories\n",
    "categories_dict = generate_categories_dict(categories)\n",
    "color_map = create_color_map(categories)\n",
    "\n",
    "num_classes = len(categories) + 1\n",
    "\n",
    "desired_input_dimensions = eval(cfg.DATA.img_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model or create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = cfg.MODEL.model_name\n",
    "\n",
    "model = load_model(model_name)\n",
    "load_params(model_name)\n",
    "\n",
    "PATH_LOG = os.path.join(cfg.DIRS.history, model_name)  # store model log\n",
    "PATH_RES = os.path.join(cfg.DIRS.results, model_name)  # store results\n",
    "\n",
    "os.makedirs(PATH_LOG, exist_ok=True)\n",
    "os.makedirs(os.path.join(PATH_RES, model_name), exist_ok=True)\n",
    "\n",
    "metadata = create_metadata(model_name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET LOADING AND PREPROCESSING === #\n",
    "X, y = preprocess_data_from_images_dev(data_path = cfg.DIRS.data, \n",
    "                                       shape = desired_input_dimensions,\n",
    "                                       categories=categories,\n",
    "                                       hspectral = [cfg.HYPERSPECTRAL.hyperspec, cfg.HYPERSPECTRAL.pca])\n",
    "\n",
    "#=== TRAIN/TEST SPLIT === #\n",
    "test_size = 1.- cfg.DATA.train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=cfg.DATA.seed)\n",
    "\n",
    "print(f'Number of TRAIN images: {len(X_train)}')\n",
    "print(f'Number of TEST images: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == INFERENCE == #\n",
    "y_pred = test_model(model, X_test, prediction_threshold=0.8)\n",
    "\n",
    "# == Confusion matrices == #\n",
    "confusion_classes, imgs_labels = evaluate.get_confusion_indices(y_test,\n",
    "                                                                y_pred,\n",
    "                                                                categories_dict=categories_dict,\n",
    "                                                                pixel_thres=10,\n",
    "                                                                meanIoU_threshold=0.7)            \n",
    "            \n",
    "for class_name,confusion_matrix in confusion_classes.items():        \n",
    "    evaluate.save_confusion_matrix(confusion_matrix, model_name, class_name, class_counter=None)\n",
    "\n",
    "clean_folder(PATH_RES)\n",
    "\n",
    "# encode ground truth and prediction masks\n",
    "y_test_en, y_pred_en = encode_masks_to_rgb(y_test, y_pred, color_map)\n",
    "save_predictions(X_test, \n",
    "                 y_test_en,\n",
    "                 y_pred_en,\n",
    "                 PATH_RES,\n",
    "                 imgs_labels,\n",
    "                 confusion_classes,\n",
    "                 color_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9bd327c0650be72877ef331820df0515ab2420b445205bbb3c4e702b19c6a4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
