{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import namegenerator as namegen\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "\n",
    "from models import evaluate\n",
    "from models.model_functions import create_model, load_model\n",
    "from models.saving import (load_params, save_losses, save_model, save_params, save_predictions)\n",
    "from models.train_test.test import test_model\n",
    "from models.train_test.train import train_model\n",
    "from processing.postprocessing import encode_masks_to_rgb, create_color_map\n",
    "from processing.preprocessing import (preprocess_data_from_images_dev, generate_categories_dict)\n",
    "from utils.dir_processing import clean_folder, save_metadata\n",
    "\n",
    "from utils.plotting import write_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_metadata(model_name):\n",
    "    \"\"\" not necessary if we use mlflow \"\"\"\n",
    "    import datetime\n",
    "    metadata = {}\n",
    "    metadata['modelname'] = model_name\n",
    "    metadata['timestamp'] = datetime.datetime.now().isoformat()\n",
    "    return metadata\n",
    "\n",
    "# Check if laptop has a GPU available for computation\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Disabling logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "with open('configs/env.yaml') as f:\n",
    "    model_env = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "categories_dict = generate_categories_dict(model_env['predictable_categories'])\n",
    "categories = model_env['predictable_categories']\n",
    "color_map = create_color_map(categories)\n",
    "\n",
    "# read config paths\n",
    "with open('configs/paths.yaml') as f:\n",
    "    paths = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "newstr = model_env['desired_input_dimensions'].replace(\"(\", \"\")\n",
    "newstr = newstr.replace(\")\",\"\")\n",
    "desired_input_dimensions = tuple(map(int, newstr.split(', ')))\n",
    "\n",
    "# == MODEL == #\n",
    "if model_env['model_name'] == '': \n",
    "    model_name = namegen.gen(separator='_')\n",
    "\n",
    "    num_classes = len(model_env['predictable_categories'])+1\n",
    "    model = create_model(desired_input_dimensions, num_classes, model_env['filters'], model_env['hyperspec'], model_env['pca'])\n",
    "    model.summary()\n",
    "else:\n",
    "    model_name = model_env['model_name']\n",
    "\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    load_params(model_name)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "metadata = create_metadata(model_name)\n",
    "\n",
    "PATH_LOG = os.path.join(paths['history_directory_path'], model_name)  # store model log\n",
    "PATH_RES = os.path.join(paths['results_directory_path'], model_name)  # store results\n",
    "\n",
    "# === DATASET LOADING AND PREPROCESSING === #\n",
    "X, y = preprocess_data_from_images_dev(data_path=paths['cleaned_data_dir_path'], \n",
    "                                       shape=desired_input_dimensions,\n",
    "                                       categories=model_env['predictable_categories'],\n",
    "                                       hspectral=[model_env['hyperspec'], model_env['pca']])\n",
    "\n",
    "#=== TRAIN/TEST SPLIT === #\n",
    "test_size = 1.-model_env['train_test_split']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=model_env['seed'])\n",
    "\n",
    "print(f'Number of TRAIN images: {len(X_train)}')\n",
    "print(f'Number of TEST images: {len(X_test)}')\n",
    "\n",
    "print('Inference mode')\n",
    "\n",
    "# == INFERENCE == #\n",
    "y_pred = test_model(model, X_test, prediction_threshold=0.8)\n",
    "#write_dataset(X_test, predictions)\n",
    "\n",
    "# == Confusion matrices == #\n",
    "confusion_classes, imgs_labels = evaluate.get_confusion_indices(y_test,\n",
    "                                                                y_pred,\n",
    "                                                                categories_dict=categories_dict,\n",
    "                                                                pixel_thres=10,\n",
    "                                                                meanIoU_threshold=0.7)            \n",
    "            \n",
    "for class_name,confusion_matrix in confusion_classes.items():        \n",
    "    evaluate.save_confusion_matrix(confusion_matrix, model_name, class_name, class_counter=None)\n",
    "\n",
    "clean_folder(PATH_RES)\n",
    "\n",
    "# encode ground truth and prediction masks\n",
    "y_test_en, y_pred_en = encode_masks_to_rgb(y_test, y_pred, color_map)\n",
    "save_predictions(X_test, \n",
    "                 y_test_en,\n",
    "                 y_pred_en,\n",
    "                 PATH_RES,\n",
    "                 imgs_labels,\n",
    "                 confusion_classes,\n",
    "                 color_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9bd327c0650be72877ef331820df0515ab2420b445205bbb3c4e702b19c6a4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
